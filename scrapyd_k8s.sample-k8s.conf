#
# Sample scrapyd-k8s configuration for a Kubernetes cluster
#
[scrapyd]
bind_address = 0.0.0.0
http_port    = 6800

# Kubernetes works with a remote repository and the Kubernetes launcher.
repository   = scrapyd_k8s.repository.Remote
launcher     = scrapyd_k8s.launcher.K8s

# Namespace to work in (needs to exist).
namespace    = scrapyd
# Optional pull secret, in case you have private spiders.
pull_secret  = ghcr-registry

# For each project, define a project section.
# This contains a repository that points to the remote container repository.
# An optional env_secret is the name of a secret with additional environment
# variables to run the spiders with; similarly env_config for a configmap.
[project.example]
env_secret   = example-env-secret
env_config   = example-env-configmap
repository   = ghcr.io/q-m/scrapyd-k8s-spider-example

#
# Resources
#
# Resource requests and limits are completely optional, so you can omit all of
# these sections if you like - though on production it is recommended to set
# them. Resources can be set at a global level, project level, and spider level.
# Each more specific level overrides any previous, so you can set limited
# default resources and give a specific project spider more headroom.

# Resource requests and limits for all projects, can be overridden per project.
[default.resources]
requests_cpu = 100m
requests_memory = 0.2G
limits_cpu = 0.8
limits_memory = 0.5G

# Resource requests and limits for the example project, can be overridden per spider.
[project.example.resources]
requests_cpu = 90m
requests_memory = 0.15G
limits_cpu = 0.6
limits_memory = 0.3G

# Resource requests and limits for a specific spider in the example project.
[project.example.quotes.resources]
requests_cpu = 80m
requests_memory = 0.12G
limits_cpu = 0.5
limits_memory = 0.2G
